{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data to feed into ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is run once all of the data (weather data and bloom/flowering data) has been collected and merged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not interested in the previous data preparation steps, simply grab `df_with_weather_data.csv` and start here, or skip to the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each location, we have 14 types of weather data by month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea: if we make prediction on a certain date, e.g. Feb 1, we won't know March 1st conditions\n",
    "we could keep those variables and set to NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- this is to predict date of **full bloom**\n",
    "- idea is to predict a whole year's batch in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pd.read_csv('../data/df_with_weather_data.csv',low_memory=False,index_col=0)\n",
    "#outputdf.rename({'blm_day':'day'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_code</th>\n",
       "      <th>l_name</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>rm</th>\n",
       "      <th>l_name_romaji</th>\n",
       "      <th>Jan_1_lag_1</th>\n",
       "      <th>Feb_1_lag_1</th>\n",
       "      <th>Mar_1_lag_1</th>\n",
       "      <th>Apr_1_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Apr_14_lag_3</th>\n",
       "      <th>May_14_lag_3</th>\n",
       "      <th>Jun_14_lag_3</th>\n",
       "      <th>Jul_14_lag_3</th>\n",
       "      <th>Aug_14_lag_3</th>\n",
       "      <th>Sep_14_lag_3</th>\n",
       "      <th>Oct_14_lag_3</th>\n",
       "      <th>Nov_14_lag_3</th>\n",
       "      <th>Dec_14_lag_3</th>\n",
       "      <th>Annual_14_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [l_code, l_name, year, day, rm, l_name_romaji, Jan_1_lag_1, Feb_1_lag_1, Mar_1_lag_1, Apr_1_lag_1, May_1_lag_1, Jun_1_lag_1, Jul_1_lag_1, Aug_1_lag_1, Sep_1_lag_1, Oct_1_lag_1, Nov_1_lag_1, Dec_1_lag_1, Annual_1_lag_1, Jan_1_lag_2, Feb_1_lag_2, Mar_1_lag_2, Apr_1_lag_2, May_1_lag_2, Jun_1_lag_2, Jul_1_lag_2, Aug_1_lag_2, Sep_1_lag_2, Oct_1_lag_2, Nov_1_lag_2, Dec_1_lag_2, Annual_1_lag_2, Jan_1_lag_3, Feb_1_lag_3, Mar_1_lag_3, Apr_1_lag_3, May_1_lag_3, Jun_1_lag_3, Jul_1_lag_3, Aug_1_lag_3, Sep_1_lag_3, Oct_1_lag_3, Nov_1_lag_3, Dec_1_lag_3, Annual_1_lag_3, Jan_2_lag_1, Feb_2_lag_1, Mar_2_lag_1, Apr_2_lag_1, May_2_lag_1, Jun_2_lag_1, Jul_2_lag_1, Aug_2_lag_1, Sep_2_lag_1, Oct_2_lag_1, Nov_2_lag_1, Dec_2_lag_1, Annual_2_lag_1, Jan_2_lag_2, Feb_2_lag_2, Mar_2_lag_2, Apr_2_lag_2, May_2_lag_2, Jun_2_lag_2, Jul_2_lag_2, Aug_2_lag_2, Sep_2_lag_2, Oct_2_lag_2, Nov_2_lag_2, Dec_2_lag_2, Annual_2_lag_2, Jan_2_lag_3, Feb_2_lag_3, Mar_2_lag_3, Apr_2_lag_3, May_2_lag_3, Jun_2_lag_3, Jul_2_lag_3, Aug_2_lag_3, Sep_2_lag_3, Oct_2_lag_3, Nov_2_lag_3, Dec_2_lag_3, Annual_2_lag_3, Jan_3_lag_1, Feb_3_lag_1, Mar_3_lag_1, Apr_3_lag_1, May_3_lag_1, Jun_3_lag_1, Jul_3_lag_1, Aug_3_lag_1, Sep_3_lag_1, Oct_3_lag_1, Nov_3_lag_1, Dec_3_lag_1, Annual_3_lag_1, Jan_3_lag_2, Feb_3_lag_2, Mar_3_lag_2, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 552 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether any flowers bloomed the year prior, i.e. 1214 or so, using approx check based on length\n",
    "outputdf.loc[((outputdf.day.str[:2]=='12') & (outputdf.day.str.len() > 3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change blooming date format, add days since year start, add blooming date lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf['year'] = outputdf.year.astype('int',errors='ignore')\n",
    "#outputdf['day'] = outputdf.day.astype('int',errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf.year.isnull().sum() # no years missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outputdf.day == '-').sum() # # of rows with missing value for bloom date, missing is denoted as - in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date(row): \n",
    "        try:\n",
    "            return(pd.datetime(row.year,int(row.day[0]),int(row.day[1:])))\n",
    "        except:\n",
    "            if (row.day[0] == '-'):\n",
    "                return(np.nan)\n",
    "            else:\n",
    "                print('unknown error')\n",
    "                return(np.nan)\n",
    "            \n",
    "def create_days_since_yr_start(row): \n",
    "        try:\n",
    "            return((row.blooming_date - pd.datetime(row.year,1,1)).days)\n",
    "        except:\n",
    "            return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l_code     int64\n",
       "l_name    object\n",
       "year       int64\n",
       "day       object\n",
       "rm        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf.dtypes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1953, 5, 30, 0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.datetime(outputdf.year[0],int(outputdf.day[0][0]),int(outputdf.day[0][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create date column\n",
    "outputdf['blooming_date'] = outputdf.apply(lambda row: create_date(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf.blooming_date.isnull().sum() # lines up with missing data count above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((outputdf.blooming_date[0] - outputdf.blooming_date[1]).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf['days_since_yr_start'] = outputdf.apply(lambda row: create_days_since_yr_start(row),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf.days_since_yr_start.isnull().sum() # lines up with missing data count above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf.loc[outputdf.year % 4 == 0,'days_since_yr_start'] += 1 # add one to leap years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue here if consecutive rows are missing, but they aren't so it's okay\n",
    "max_lag = 3\n",
    "for lag in range(1,max_lag + 1):\n",
    "    outputdf[f'days_lag_minus_{lag}'] = outputdf.groupby(['l_code'])['days_since_yr_start'].transform(lambda x: x.shift(-lag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041\n",
      "1120\n",
      "1199\n"
     ]
    }
   ],
   "source": [
    "# sanity check on null values for blooming date lags\n",
    "for lag in range(1,max_lag + 1):\n",
    "    print(outputdf[f'days_lag_minus_{lag}'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder of Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want our data frame to look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloom_days</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>last_yr_{WEATHER}_month</th>\n",
       "      <th>last_yr_bloom_days</th>\n",
       "      <th>2_yr_bloom_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bloom_days, location, year, last_yr_{WEATHER}_month, last_yr_bloom_days, 2_yr_bloom_days]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([],columns=['bloom_days','location','year','last_yr_{WEATHER}_month','last_yr_bloom_days','2_yr_bloom_days'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Missing Values (after creating the lags(!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = outputdf.loc[outputdf.day != \"-\"] # remove rows with missing bloom date\n",
    "# must do this after we set the lags so we don't eliminate years and mess up lag calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_code</th>\n",
       "      <th>l_name</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>rm</th>\n",
       "      <th>l_name_romaji</th>\n",
       "      <th>Jan_1_lag_1</th>\n",
       "      <th>Feb_1_lag_1</th>\n",
       "      <th>Mar_1_lag_1</th>\n",
       "      <th>Apr_1_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Sep_14_lag_3</th>\n",
       "      <th>Oct_14_lag_3</th>\n",
       "      <th>Nov_14_lag_3</th>\n",
       "      <th>Dec_14_lag_3</th>\n",
       "      <th>Annual_14_lag_3</th>\n",
       "      <th>blooming_date</th>\n",
       "      <th>days_since_yr_start</th>\n",
       "      <th>days_lag_minus_1</th>\n",
       "      <th>days_lag_minus_2</th>\n",
       "      <th>days_lag_minus_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>936</td>\n",
       "      <td>那覇</td>\n",
       "      <td>2017</td>\n",
       "      <td>208</td>\n",
       "      <td>7</td>\n",
       "      <td>NAHA</td>\n",
       "      <td>17.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>936</td>\n",
       "      <td>那覇</td>\n",
       "      <td>2018</td>\n",
       "      <td>130</td>\n",
       "      <td>7</td>\n",
       "      <td>NAHA</td>\n",
       "      <td>18.4</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>21.6</td>\n",
       "      <td>...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>945</td>\n",
       "      <td>南大東島</td>\n",
       "      <td>2016</td>\n",
       "      <td>301</td>\n",
       "      <td>7</td>\n",
       "      <td>MINAMI DAITOJIMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>61.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>945</td>\n",
       "      <td>南大東島</td>\n",
       "      <td>2017</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>MINAMI DAITOJIMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731</th>\n",
       "      <td>945</td>\n",
       "      <td>南大東島</td>\n",
       "      <td>2018</td>\n",
       "      <td>129</td>\n",
       "      <td>7</td>\n",
       "      <td>MINAMI DAITOJIMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 557 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l_code l_name  year  day rm     l_name_romaji Jan_1_lag_1 Feb_1_lag_1  \\\n",
       "6724     936     那覇  2017  208  7              NAHA        17.4        16.9   \n",
       "6725     936     那覇  2018  130  7              NAHA        18.4        17.1   \n",
       "6729     945   南大東島  2016  301  7  MINAMI DAITOJIMA         NaN         NaN   \n",
       "6730     945   南大東島  2017  214  7  MINAMI DAITOJIMA         NaN         NaN   \n",
       "6731     945   南大東島  2018  129  7  MINAMI DAITOJIMA         NaN         NaN   \n",
       "\n",
       "     Mar_1_lag_1 Apr_1_lag_1       ...        Sep_14_lag_3 Oct_14_lag_3  \\\n",
       "6724        18.7        23.0       ...                  --           --   \n",
       "6725        18.3        21.6       ...                  --           --   \n",
       "6729         NaN         NaN       ...                 NaN          NaN   \n",
       "6730         NaN         NaN       ...                 NaN          NaN   \n",
       "6731         NaN         NaN       ...                 NaN          NaN   \n",
       "\n",
       "     Nov_14_lag_3 Dec_14_lag_3 Annual_14_lag_3 blooming_date  \\\n",
       "6724           --           --              --    2017-02-08   \n",
       "6725           --           --              --    2018-01-30   \n",
       "6729          NaN          NaN             NaN    2016-03-01   \n",
       "6730          NaN          NaN             NaN    2017-02-14   \n",
       "6731          NaN          NaN             NaN    2018-01-29   \n",
       "\n",
       "     days_since_yr_start days_lag_minus_1 days_lag_minus_2 days_lag_minus_3  \n",
       "6724                38.0             29.0              NaN              NaN  \n",
       "6725                29.0              NaN              NaN              NaN  \n",
       "6729                61.0             44.0             28.0              NaN  \n",
       "6730                44.0             28.0              NaN              NaN  \n",
       "6731                28.0              NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 557 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall TO DO's:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to exclude any locations where the flowers bloom before the start of the year, to make things simpler (because we would need to remove previous years lags to deal with those cases)\n",
    "\n",
    "DONE at beginning this wasn't an issue\n",
    "- We want to check what data is missing and which locations should be removed due to lack of data:\n",
    "\n",
    "Removed rows with NA blooming date. everything else can be flagged with a `var_nameISNA` column\n",
    "- We want to add a flowering day lag indicator\n",
    "\n",
    "DONE\n",
    "- We want to recode flowering date as days from Jan 1st (will need to add plus one every leap year (2000 +- 4)\n",
    "\n",
    "DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one batch prediction for the whole year (like you were planning a vacation far in advance and wanted to get an idea of the flower blossom forecast in January)\n",
    "- model with Neural Nets for tabular data like Rossman comp fastai model\n",
    "- could also try decision tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf['rownullsums'] = outputdf.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_locs = outputdf.groupby('l_code').rownullsums.apply(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are several problematic locations that it looks like weather data was unavailable for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l_code\n",
       "433    546.215686\n",
       "435    546.115385\n",
       "597    546.133333\n",
       "612    546.109091\n",
       "631    546.113208\n",
       "648    546.090909\n",
       "663    546.109091\n",
       "740    546.107143\n",
       "744    546.109091\n",
       "747    546.109091\n",
       "776    546.183673\n",
       "778    546.180000\n",
       "800    546.105263\n",
       "837    546.820513\n",
       "909    546.300000\n",
       "917    546.625000\n",
       "945    546.452381\n",
       "Name: rownullsums, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_locs[problem_locs>500] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could consider removing these locations for further analysis. I will do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_codes_missing_weather = problem_locs[problem_locs>500].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_keep_remove_missing_weather = outputdf.l_code.apply(lambda x: x not in l_codes_missing_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = outputdf.loc[rows_to_keep_remove_missing_weather,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat weather data using quality notes from JP website\n",
    "\n",
    "(https://www.data.jma.go.jp/obd/stats/data/en/smp/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Format|Example|Validity|Notes|\n",
    "--- | --- | --- | ---\n",
    "    |Value) |\t11.5)\t| Quasi-Reliable\t| Only slight problems were found in the automatic quality control, or the value was computed from the dataset with a few missing data.\n",
    "Value] |\t11.5]\t| Incomplete\t| The value was computed from a dataset with excessive missing data.\n",
    "-\t| - |\tNo phenomenon\t| No phenomenon was ovserved within the period.\n",
    "X\t| X\t| Missing\t| No value is available due to problems with observation instruments, etc.\n",
    "Blank| &nbsp;  |\t\tOut of observation |\tNo observation was conducted.\n",
    "*\t| 31* |\tMost recent extreme values |\tThe value is the most recently observed of those two or more identical daily extreme values in the period.\n",
    "#\t| #\t| Suspicious |\tA serious quality problem was found in the value, treated as omitted from the statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand weather data validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdataissues = dict(zip(['quasireliable','incomplete','no_phenom', 'missing', 'no_obs','extreme', 'suspicious'],\n",
    "                         [[0,')'],\n",
    "                          [0,']'],\n",
    "                          [0,'-'],\n",
    "                          [0,'X'],\n",
    "                          [0,''],\n",
    "                          [0,'*'],\n",
    "                          [0,'#']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_abrevs = [i for i in calendar.month_abbr[1:]]; month_abrevs.append('Annual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cols = [i for i in df.columns if month_abrevs.count(i.split(\"_\")[0])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l_code         int64\n",
       "year           int64\n",
       "day            int64\n",
       "rm             int64\n",
       "rownullsums    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf.dtypes[outputdf.dtypes=='int64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 null vals for col Aug_9_lag_2\n",
      "22 null vals for col Sep_9_lag_2\n",
      "22 null vals for col Oct_9_lag_2\n",
      "41 null vals for col Aug_9_lag_3\n",
      "41 null vals for col Sep_9_lag_3\n",
      "41 null vals for col Oct_9_lag_3\n"
     ]
    }
   ],
   "source": [
    "for col in weather_cols:\n",
    "    for key in weatherdataissues.keys():\n",
    "        # first element of list of values is count of that problem, second is the identifying punct\n",
    "        # add to count the number observed in that column\n",
    "        try:\n",
    "            weatherdataissues[key][0] += outputdf[col].str.endswith(weatherdataissues[key][1]).sum()\n",
    "        except AttributeError:\n",
    "            # if the col is a float then there are no missing issues here so we can continue\n",
    "            print(f'{outputdf[col].isnull().sum()} null vals for col {col}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quasireliable': [20295, ')'],\n",
       " 'incomplete': [1029, ']'],\n",
       " 'no_phenom': [108425, '-'],\n",
       " 'missing': [0, 'X'],\n",
       " 'no_obs': [2578816, ''],\n",
       " 'extreme': [0, '*'],\n",
       " 'suspicious': [0, '#']}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdataissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't appear to be major issues with data validity. I'm not going to add separate columns for each data issue to the main data frame for now. Instead I will scrape away punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove weather data quality markings, convert cols to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to iterate over each column\n",
    "    use a series method to remove any special characters\n",
    "    if the value is '-' need to something special to indicate no phenomenon, try -1000 for now\n",
    "    if value 'X' need to replace with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for col in weather_cols:\n",
    "    x = outputdf[col].replace('\\-$','1000',regex=True) # coerce to nmeric indicator for no phenom\n",
    "    x = x.replace('×',np.nan) # missing\n",
    "    x = x.replace(r' [\\)\\]]$','',regex=True) # remove quality indicator\n",
    "    x = x.replace(r'^\\s','1000',regex=True) # coerce to numeric indicator for no obs conducted\n",
    "    outputdf[col] = x\n",
    "    outputdf[col].astype('float64',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf.to_csv('../data/data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
